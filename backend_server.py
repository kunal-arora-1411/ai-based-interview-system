#!/usr/bin/env python3
"""
FastAPI Backend Server for AI Interview Platform

Connects the React frontend with the LangChain-based interview system (new_llm_inter.py)
Provides REST API and WebSocket endpoints for real-time interview sessions.

Usage:
    python backend_server.py

Then access:
    - API docs: http://localhost:8000/docs
    - Frontend: http://localhost:5173
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, Dict, List, Any
import json
import os
import pathlib
import asyncio
import io
import tempfile
import time
from datetime import datetime
from dotenv import load_dotenv
import whisper
import pyttsx3
import threading
import soundfile as sf
import numpy as np
from pydub import AudioSegment

# Import the interview system
from new_llm_inter import (
    InterviewChainManager,
    InterviewSession,
    load_sample,
    select_competency,
    band_from_score,
    append_record
)

load_dotenv()

# Initialize FastAPI
app = FastAPI(
    title="AI Interview Platform API",
    description="Backend API for the AI-powered interview platform",
    version="1.0.0"
)

# CORS middleware - allow frontend to connect
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# Data Models
# ============================================================================

class InterviewStartRequest(BaseModel):
    mode: str = "practice"  # 'practice' or 'official'
    sample_idx: int = 0
    competency: Optional[str] = None
    rounds: int = 3

class AnswerSubmission(BaseModel):
    session_id: str
    answer: str
    question: str

class CVUpload(BaseModel):
    content: str
    filename: str

class JobDescriptionUpload(BaseModel):
    content: str

class TextToSpeechRequest(BaseModel):
    text: str
    voice: str = "alloy"  # Options: alloy, echo, fable, onyx, nova, shimmer

# ============================================================================
# In-Memory Session Storage
# ============================================================================

class SessionManager:
    """Manages active interview sessions"""

    def __init__(self):
        self.sessions: Dict[str, Dict[str, Any]] = {}

    def create_session(self, session_id: str, config: dict) -> dict:
        """Create a new interview session"""
        self.sessions[session_id] = {
            "session_id": session_id,
            "created_at": datetime.now().isoformat(),
            "config": config,
            "current_question": None,
            "current_round": 0,
            "questions_asked": [],
            "answers_received": [],
            "scores": [],
            "chain_manager": None,
            "competency": None,
            "sample_data": None,
            "status": "created"  # created, active, completed
        }
        return self.sessions[session_id]

    def get_session(self, session_id: str) -> Optional[dict]:
        """Get session by ID"""
        return self.sessions.get(session_id)

    def update_session(self, session_id: str, updates: dict):
        """Update session data"""
        if session_id in self.sessions:
            self.sessions[session_id].update(updates)

    def delete_session(self, session_id: str):
        """Delete a session"""
        if session_id in self.sessions:
            del self.sessions[session_id]

session_manager = SessionManager()

# ============================================================================
# Helper Functions
# ============================================================================

def initialize_chain_manager() -> InterviewChainManager:
    """Initialize the LangChain interview manager"""
    model_name = os.getenv("LLM_MODEL", "llama-3.3-70b-versatile")
    api_key = os.getenv("LLM_API_KEY")
    base_url = os.getenv("LLM_BASE_URL", None)

    if not api_key:
        raise HTTPException(status_code=500, detail="LLM_API_KEY not configured")

    return InterviewChainManager(
        model_name=model_name,
        api_key=api_key,
        base_url=base_url
    )

# Global Whisper model (loaded once for performance)
whisper_model = None

def get_whisper_model():
    """Load Whisper model (cached globally)"""
    global whisper_model
    if whisper_model is None:
        # Load base model (faster, good accuracy)
        # Options: tiny, base, small, medium, large
        model_size = os.getenv("WHISPER_MODEL", "base")
        print(f"Loading Whisper model: {model_size}...")
        whisper_model = whisper.load_model(model_size)
        print("Whisper model loaded!")
    return whisper_model

# ============================================================================
# REST API Endpoints
# ============================================================================

@app.get("/")
async def root():
    """API root endpoint"""
    return {
        "message": "AI Interview Platform API",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/interviews/start")
async def start_interview(request: InterviewStartRequest):
    """
    Start a new interview session

    Returns session_id and first question
    """
    try:
        # Generate session ID
        session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"

        # Load sample data
        input_file = "data/training/rubrics_filled.jsonl"
        sample = load_sample(input_file, request.sample_idx)

        # Select competency
        competency = select_competency(
            sample.get("rubric", {}),
            request.competency
        )

        # Initialize chain manager
        chain_manager = initialize_chain_manager()

        # Generate first question
        q_output = chain_manager.generate_question(
            sample.get("jd", ""),
            sample.get("resume", ""),
            competency.get("name", "")
        )

        # Create session
        session = session_manager.create_session(session_id, {
            "mode": request.mode,
            "sample_idx": request.sample_idx,
            "rounds": request.rounds,
            "competency_name": request.competency
        })

        # Update session with initialized data
        session_manager.update_session(session_id, {
            "chain_manager": chain_manager,
            "competency": competency,
            "sample_data": sample,
            "current_question": q_output.question,
            "current_round": 1,
            "status": "active"
        })

        return {
            "session_id": session_id,
            "competency": competency.get("name", ""),
            "question": q_output.question,
            "difficulty": q_output.difficulty,
            "round": 1,
            "total_rounds": request.rounds
        }

    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Sample data file not found")
    except IndexError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start interview: {str(e)}")

@app.post("/api/interviews/answer")
async def submit_answer(submission: AnswerSubmission):
    """
    Submit an answer and get grading + next question
    """
    try:
        session = session_manager.get_session(submission.session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")

        chain_manager = session["chain_manager"]
        competency = session["competency"]
        current_round = session["current_round"]
        total_rounds = session["config"]["rounds"]

        # Grade the answer
        grade_output = chain_manager.grade_answer(
            submission.question,
            submission.answer,
            competency
        )

        # Rewrite follow-up
        followup = chain_manager.rewrite_followup(grade_output.followup_question)

        # Calculate band
        band = band_from_score(grade_output.score)

        # Store the Q&A record
        record = {
            "session_id": submission.session_id,
            "round": current_round,
            "competency": competency.get("name", ""),
            "question": submission.question,
            "answer": submission.answer,
            "score": grade_output.score,
            "band": band,
            "justification": grade_output.justification,
            "followup_question": followup,
            "timestamp": datetime.now().isoformat()
        }

        # Append to session history
        session["questions_asked"].append(submission.question)
        session["answers_received"].append(submission.answer)
        session["scores"].append(grade_output.score)

        # Save to file
        output_path = pathlib.Path("data/training/evals.jsonl")
        append_record(output_path, record)

        # Check if interview is complete
        is_complete = current_round >= total_rounds

        if not is_complete:
            # Update session for next round
            session_manager.update_session(submission.session_id, {
                "current_question": followup,
                "current_round": current_round + 1
            })
        else:
            # Mark session as completed
            session_manager.update_session(submission.session_id, {
                "status": "completed"
            })

        return {
            "score": grade_output.score,
            "band": band,
            "justification": grade_output.justification,
            "next_question": followup if not is_complete else None,
            "round": current_round + 1,
            "total_rounds": total_rounds,
            "is_complete": is_complete
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to process answer: {str(e)}")

@app.get("/api/interviews/{session_id}/feedback")
async def get_feedback(session_id: str):
    """
    Get comprehensive feedback for a completed interview session
    """
    try:
        session = session_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")

        if session["status"] != "completed":
            raise HTTPException(status_code=400, detail="Interview not yet completed")

        # Calculate statistics
        scores = session["scores"]
        avg_score = sum(scores) / len(scores) if scores else 0
        avg_band = band_from_score(avg_score)

        # Read the eval records for this session
        evals = []
        eval_file = pathlib.Path("data/training/evals.jsonl")
        if eval_file.exists():
            with eval_file.open("r", encoding="utf-8") as f:
                for line in f:
                    record = json.loads(line)
                    if record.get("session_id") == session_id:
                        evals.append(record)

        return {
            "session_id": session_id,
            "competency": session["competency"].get("name", ""),
            "total_questions": len(session["questions_asked"]),
            "average_score": round(avg_score, 2),
            "average_band": avg_band,
            "scores": scores,
            "evaluations": evals,
            "created_at": session["created_at"],
            "completed_at": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get feedback: {str(e)}")

@app.get("/api/interviews/history")
async def get_interview_history():
    """
    Get all completed interview sessions
    """
    try:
        history = []

        # Read all eval records
        eval_file = pathlib.Path("data/training/evals.jsonl")
        if eval_file.exists():
            sessions_data = {}

            with eval_file.open("r", encoding="utf-8") as f:
                for line in f:
                    record = json.loads(line)
                    session_id = record.get("session_id", "unknown")

                    if session_id not in sessions_data:
                        sessions_data[session_id] = {
                            "session_id": session_id,
                            "competency": record.get("competency", ""),
                            "scores": [],
                            "timestamp": record.get("timestamp", "")
                        }

                    sessions_data[session_id]["scores"].append(record.get("score", 0))

            # Calculate averages and format
            for session_id, data in sessions_data.items():
                scores = data["scores"]
                avg_score = sum(scores) / len(scores) if scores else 0

                history.append({
                    "session_id": session_id,
                    "competency": data["competency"],
                    "questions_answered": len(scores),
                    "average_score": round(avg_score, 2),
                    "average_band": band_from_score(avg_score),
                    "timestamp": data["timestamp"]
                })

        # Sort by timestamp (newest first)
        history.sort(key=lambda x: x["timestamp"], reverse=True)

        return {"history": history}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get history: {str(e)}")

@app.post("/api/cv/upload")
async def upload_cv(file: UploadFile = File(...)):
    """
    Upload and parse CV file
    """
    try:
        content = await file.read()
        text_content = content.decode("utf-8")

        # For now, return mock parsing result
        # In production, you'd use a real CV parser
        return {
            "success": True,
            "filename": file.filename,
            "extracted_skills": [
                "Python", "JavaScript", "React", "Machine Learning",
                "FastAPI", "SQL", "Git", "Problem Solving"
            ],
            "experience_years": 3,
            "education": "Bachelor's in Computer Science"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to process CV: {str(e)}")

@app.post("/api/jd/parse")
async def parse_job_description(jd: JobDescriptionUpload):
    """
    Parse job description text
    """
    try:
        # For now, return mock parsing result
        # In production, you'd use NLP to extract requirements
        return {
            "success": True,
            "required_skills": [
                "Python", "React", "System Design", "Communication",
                "Problem Solving", "Leadership"
            ],
            "experience_required": "3-5 years",
            "role_level": "Mid-Senior"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to parse JD: {str(e)}")

@app.delete("/api/interviews/{session_id}")
async def end_interview(session_id: str):
    """
    End an interview session
    """
    try:
        session = session_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")

        session_manager.delete_session(session_id)

        return {
            "success": True,
            "message": "Interview session ended",
            "session_id": session_id
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to end interview: {str(e)}")

# ============================================================================
# Speech-to-Text (Whisper) Endpoint
# ============================================================================

@app.post("/api/speech/transcribe")
async def transcribe_audio(file: UploadFile = File(...)):
    """
    Transcribe audio using local Whisper model

    Accepts audio files (mp3, mp4, mpeg, mpga, m4a, wav, webm)
    Returns transcribed text
    """
    try:
        # Get Whisper model
        model = get_whisper_model()

        # Read audio file
        audio_data = await file.read()

        # Create a temporary file with the correct extension
        file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'webm'

        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as temp_file:
            temp_file.write(audio_data)
            temp_file_path = temp_file.name

        # Store paths for cleanup
        wav_path = None

        try:
            # For WebM files, try direct transcription first (Whisper handles it if ffmpeg is available)
            if file_extension == 'webm':
                try:
                    # Let Whisper handle the WebM file directly
                    result = model.transcribe(temp_file_path, fp16=False)
                    transcript = result["text"].strip()

                    return {
                        "success": True,
                        "text": transcript,
                        "filename": file.filename,
                        "language": result.get("language", "unknown")
                    }
                except Exception as webm_error:
                    print(f"⚠️ WebM direct transcription failed: {webm_error}")
                    print("💡 Trying alternative audio processing...")

                    # Try pydub conversion as fallback
                    try:
                        audio = AudioSegment.from_file(temp_file_path, format='webm')
                        wav_path = temp_file_path.replace('.webm', '.wav')
                        audio.export(wav_path, format='wav')

                        # Read with soundfile
                        audio_data, sample_rate = sf.read(wav_path)

                        # Convert to mono if stereo
                        if len(audio_data.shape) > 1:
                            audio_data = audio_data.mean(axis=1)

                        # Resample to 16kHz if needed
                        if sample_rate != 16000:
                            import librosa
                            audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)

                        # Normalize to float32
                        audio_data = audio_data.astype(np.float32)

                        # Transcribe
                        result = model.transcribe(audio_data, fp16=False)
                        transcript = result["text"].strip()

                        return {
                            "success": True,
                            "text": transcript,
                            "filename": file.filename,
                            "language": result.get("language", "unknown")
                        }
                    except Exception as conv_error:
                        print(f"❌ Audio conversion failed: {conv_error}")
                        raise HTTPException(
                            status_code=500,
                            detail="WebM audio processing failed. Please install FFmpeg or use a different audio format."
                        )
            else:
                # For non-WebM formats, use soundfile directly
                try:
                    audio_data, sample_rate = sf.read(temp_file_path)

                    # Convert to mono if stereo
                    if len(audio_data.shape) > 1:
                        audio_data = audio_data.mean(axis=1)

                    # Resample to 16kHz if needed
                    if sample_rate != 16000:
                        import librosa
                        audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)

                    # Normalize to float32
                    audio_data = audio_data.astype(np.float32)

                    # Transcribe
                    result = model.transcribe(audio_data, fp16=False)
                    transcript = result["text"].strip()

                    return {
                        "success": True,
                        "text": transcript,
                        "filename": file.filename,
                        "language": result.get("language", "unknown")
                    }
                except Exception as audio_error:
                    print(f"Audio processing error: {audio_error}")
                    # Fallback to Whisper's built-in loader
                    result = model.transcribe(temp_file_path, fp16=False)
                    transcript = result["text"].strip()

                    return {
                        "success": True,
                        "text": transcript,
                        "filename": file.filename,
                        "language": result.get("language", "unknown")
                    }

        finally:
            # Clean up temp files with proper error handling
            time.sleep(0.1)  # Small delay to ensure file handles are released

            if wav_path and os.path.exists(wav_path):
                try:
                    os.unlink(wav_path)
                except Exception as e:
                    print(f"⚠️ Could not delete temp WAV file: {e}")

            if os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                except Exception as e:
                    print(f"⚠️ Could not delete temp file: {e}")

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Failed to transcribe audio: {str(e)}")

# ============================================================================
# Text-to-Speech (TTS) Endpoint
# ============================================================================

# TTS lock to prevent concurrent access
tts_lock = threading.Lock()

@app.post("/api/speech/synthesize")
async def synthesize_speech(request: TextToSpeechRequest):
    """
    Convert text to speech using local pyttsx3

    Returns audio stream (mp3)
    """
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_path = temp_file.name

        try:
            # Use threading lock to prevent concurrent TTS calls
            with tts_lock:
                # Initialize TTS engine
                engine = pyttsx3.init()

                # Set voice based on request
                voices = engine.getProperty('voices')
                if request.voice == 'nova' or request.voice == 'shimmer':
                    # Try to find a female voice
                    for voice in voices:
                        if 'female' in voice.name.lower() or 'zira' in voice.name.lower():
                            engine.setProperty('voice', voice.id)
                            break
                else:
                    # Use default or male voice
                    for voice in voices:
                        if 'male' in voice.name.lower() or 'david' in voice.name.lower():
                            engine.setProperty('voice', voice.id)
                            break

                # Set speech rate (words per minute)
                engine.setProperty('rate', 150)  # Normal speed

                # Save to file
                engine.save_to_file(request.text, temp_path)
                engine.runAndWait()

            # Read the generated audio file
            with open(temp_path, 'rb') as audio_file:
                audio_data = audio_file.read()

            # Return as streaming response
            return StreamingResponse(
                io.BytesIO(audio_data),
                media_type="audio/wav",
                headers={
                    "Content-Disposition": "inline; filename=speech.wav"
                }
            )

        finally:
            # Clean up temp file
            if os.path.exists(temp_path):
                try:
                    os.unlink(temp_path)
                except:
                    pass  # File might still be in use

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Failed to synthesize speech: {str(e)}")

# ============================================================================
# WebSocket Endpoint for Real-Time Interview
# ============================================================================

@app.websocket("/ws/interview/{session_id}")
async def websocket_interview(websocket: WebSocket, session_id: str):
    """
    WebSocket endpoint for real-time interview interaction

    Message format:
    {
        "type": "answer" | "status" | "ping",
        "data": {...}
    }
    """
    await websocket.accept()

    try:
        session = session_manager.get_session(session_id)
        if not session:
            await websocket.send_json({
                "type": "error",
                "message": "Session not found"
            })
            await websocket.close()
            return

        # Send initial question
        await websocket.send_json({
            "type": "question",
            "data": {
                "question": session["current_question"],
                "round": session["current_round"],
                "total_rounds": session["config"]["rounds"]
            }
        })

        # Listen for messages
        while True:
            message = await websocket.receive_json()
            msg_type = message.get("type")

            if msg_type == "answer":
                # Process answer submission
                data = message.get("data", {})
                answer = data.get("answer", "")

                if not answer:
                    await websocket.send_json({
                        "type": "error",
                        "message": "Empty answer"
                    })
                    continue

                # Send thinking status
                await websocket.send_json({
                    "type": "status",
                    "data": {"ai_state": "thinking"}
                })

                # Grade the answer
                chain_manager = session["chain_manager"]
                competency = session["competency"]
                current_question = session["current_question"]

                grade_output = chain_manager.grade_answer(
                    current_question,
                    answer,
                    competency
                )

                followup = chain_manager.rewrite_followup(grade_output.followup_question)
                band = band_from_score(grade_output.score)

                # Store record
                current_round = session["current_round"]
                record = {
                    "session_id": session_id,
                    "round": current_round,
                    "competency": competency.get("name", ""),
                    "question": current_question,
                    "answer": answer,
                    "score": grade_output.score,
                    "band": band,
                    "justification": grade_output.justification,
                    "followup_question": followup,
                    "timestamp": datetime.now().isoformat()
                }

                output_path = pathlib.Path("data/training/evals.jsonl")
                append_record(output_path, record)

                # Update session
                session["questions_asked"].append(current_question)
                session["answers_received"].append(answer)
                session["scores"].append(grade_output.score)

                # Check if complete
                total_rounds = session["config"]["rounds"]
                is_complete = current_round >= total_rounds

                if not is_complete:
                    session_manager.update_session(session_id, {
                        "current_question": followup,
                        "current_round": current_round + 1
                    })
                else:
                    session_manager.update_session(session_id, {
                        "status": "completed"
                    })

                # Send grading result
                await websocket.send_json({
                    "type": "grading",
                    "data": {
                        "score": grade_output.score,
                        "band": band,
                        "justification": grade_output.justification
                    }
                })

                # Send next question or completion
                if not is_complete:
                    await websocket.send_json({
                        "type": "question",
                        "data": {
                            "question": followup,
                            "round": current_round + 1,
                            "total_rounds": total_rounds
                        }
                    })
                else:
                    await websocket.send_json({
                        "type": "complete",
                        "data": {
                            "session_id": session_id,
                            "average_score": sum(session["scores"]) / len(session["scores"])
                        }
                    })

            elif msg_type == "ping":
                await websocket.send_json({
                    "type": "pong"
                })

    except WebSocketDisconnect:
        print(f"WebSocket disconnected for session {session_id}")
    except Exception as e:
        print(f"WebSocket error: {e}")
        await websocket.send_json({
            "type": "error",
            "message": str(e)
        })

# ============================================================================
# Run Server
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    print("\n" + "="*60)
    print("🚀 AI Interview Platform Backend Server")
    print("="*60)
    print(f"📡 API Server: http://localhost:8000")
    print(f"📚 API Docs: http://localhost:8000/docs")
    print(f"🎨 Frontend: http://localhost:5173")
    print("="*60 + "\n")

    uvicorn.run(
        "backend_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
